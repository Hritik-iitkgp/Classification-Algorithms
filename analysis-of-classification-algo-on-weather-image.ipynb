{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2854929,"sourceType":"datasetVersion","datasetId":1715246}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# step1 label the file name with their labels in it\nimport os\nimport pandas as pd\ndata_dir = '/kaggle/input/weather-dataset/dataset'\npaths = []\nclassLabels = []\n# list the directories of folders within the dataset\nfolders = os.listdir(data_dir)\n# iteratate through each of the directories classes\nfor folder in folders:\n    # for each class iterate through each of the images in it\n    foldpath = os.path.join(data_dir, folder)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        # for each image add it location to paths list\n        fpath = os.path.join(foldpath, file)\n        paths.append(fpath)\n        # and  class label as the name of folder in classlabel list\n        classLabels.append(folder)\n\n# Concatenate data paths with labels into one dataframe\ndf = pd.DataFrame(list(zip(paths, classLabels)),columns =['filePaths', 'label'])","metadata":{"execution":{"iopub.status.busy":"2023-12-09T14:08:03.617414Z","iopub.execute_input":"2023-12-09T14:08:03.618468Z","iopub.status.idle":"2023-12-09T14:08:05.403931Z","shell.execute_reply.started":"2023-12-09T14:08:03.618409Z","shell.execute_reply":"2023-12-09T14:08:05.402614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# few instances of dataset\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T14:08:05.406813Z","iopub.execute_input":"2023-12-09T14:08:05.407781Z","iopub.status.idle":"2023-12-09T14:08:05.435268Z","shell.execute_reply.started":"2023-12-09T14:08:05.407733Z","shell.execute_reply":"2023-12-09T14:08:05.433674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of images in each class\ndf['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T14:08:05.436691Z","iopub.execute_input":"2023-12-09T14:08:05.437564Z","iopub.status.idle":"2023-12-09T14:08:05.458881Z","shell.execute_reply.started":"2023-12-09T14:08:05.437524Z","shell.execute_reply":"2023-12-09T14:08:05.457750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting feature from images\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nimport numpy as np\n# Using the Tensorflow to extract freatue\n# using the pretrained model of VGG16 which is an cnn for image dataset \n# extracting by removing the last layer of model\n\n#step1.1 Loading the pre-trained VGG16 model\nmodel = VGG16(weights='imagenet', include_top=False)\n\ndef extract_features(img_path):\n    #  resizing all images in 244*244 size\n    img = image.load_img(img_path, target_size=(224, 224))\n    # convert the image to array\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    # preprocess the array as the input required for the vgg16 model\n    # using the function preprocess_input\n    img_array = preprocess_input(img_array)\n    features = model.predict(img_array)\n    # return the feature extracted\n    return features.flatten()\n\n# for each image find its feature extract from above funtion and store them as a list\nimg_features = list(map(extract_features,paths))\nprint(len(img_features))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T14:08:05.461783Z","iopub.execute_input":"2023-12-09T14:08:05.462629Z","iopub.status.idle":"2023-12-09T14:50:35.324957Z","shell.execute_reply.started":"2023-12-09T14:08:05.462576Z","shell.execute_reply":"2023-12-09T14:50:35.323454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#step 2\n# split the dataset in 80 for train 10 for test and 10 for validation\n# split in 80 and 20\nX_train, X_temp, y_train, y_temp = train_test_split(img_features, classLabels, test_size=0.2, random_state=42)\n# from 20 again split 10 for validation and 10 for testing\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T14:50:35.326626Z","iopub.execute_input":"2023-12-09T14:50:35.327000Z","iopub.status.idle":"2023-12-09T14:50:35.875148Z","shell.execute_reply.started":"2023-12-09T14:50:35.326966Z","shell.execute_reply":"2023-12-09T14:50:35.873690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#step 3\n# import the classifiers  GaussianNB , DecisionTreeClassifier , SVC from sklearn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n# run and train gussion naive bayes\nnaive_Bayes = GaussianNB()\nnaive_Bayes.fit(X_train, y_train)\n# predict using the trained naive_Bayes for X_test and X_val\nnb_test = naive_Bayes.predict(X_test)\nnb_val=naive_Bayes.predict(X_val)\n\n# run and train Decision Tree\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\n# predict using the trained Decision Tree for X_test and X_val\ndt_test = dt.predict(X_test)\ndt_val = dt.predict(X_val)\n\n# run and train SVM\nsvm = SVC(probability=True)\nsvm.fit(X_train, y_train)\n# predict using the trained SVM for X_test and X_val\nsvm_test = svm.predict(X_test)\nsvm_val = svm.predict(X_val)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T14:50:35.877477Z","iopub.execute_input":"2023-12-09T14:50:35.878093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step 4\n# import the different measures to evaluate the model\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\ndef printReport(y_true, y_pred, model_name):\n    \"\"\"\n    This funtion will compute the different matrices for each of the model \n    and print the accuracy , preission , recall ,f1 score , auc roc curve, confussion matrix \n    \"\"\"\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred,average=\"weighted\")\n    recall = recall_score(y_true, y_pred,average=\"weighted\")\n    f1 = f1_score(y_true, y_pred,average=\"weighted\")\n    confusion_mat = confusion_matrix(y_true, y_pred)\n\n    print(\"Metrics for \",model_name,\":\\n\")\n    print(\"Accuracy:\",accuracy)\n    print(\"Precision:\",precision)\n    print(\"Recall:\",recall)\n    print(\"F1-Score:\",f1)\n    print(\"Confusion Matrix:\")\n    print(confusion_mat)\n\n# Evaluate on validation dataset for each of model\nprintReport(y_val, nb_val, 'Gaaussian Naive Bayes on validation data set')\nprint(\"---------------------------------------------------------------------------\\n\")\nprintReport(y_val, dt_val, 'Decision Tree on validation data set')\nprint(\"---------------------------------------------------------------------------\\n\")\nprintReport(y_val, svm_val, 'SVM on validation data set')\n# Evaluate on test dataset for each of model\nprint(\"---------------------------------------------------------------------------\\n\")\nprintReport(y_test, nb_test, 'Gaaussian Naive Bayes on test data set')\nprint(\"---------------------------------------------------------------------------\\n\")\nprintReport(y_test, dt_test, 'Decision Tree on test data set')\nprint(\"---------------------------------------------------------------------------\\n\")\nprintReport(y_test, svm_test, 'SVM on test data set')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}